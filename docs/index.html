<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Diffusion Model Guided Sampling</title>
  <!-- Inline CSS styling for a single-page website (inspired by DepthFM style) -->
  <style>
    /* Base reset and styling */
    * {
      margin: 0; 
      padding: 0; 
      box-sizing: border-box; 
      font-family: "Helvetica Neue", Arial, sans-serif;
    }

    body {
      background: #ffffff; 
      color: #333333; 
      font-size: 16px;
      line-height: 1.6;
    }

    a {
      color: #0066cc;
      text-decoration: none;
    }
    
    a:hover {
      text-decoration: underline;
    }

    /* Container and layout */
    .container {
      width: 90%;
      max-width: 1000px;
      margin: 0 auto;
      padding: 2rem 0;
    }

    header {
      text-align: center;
      margin-bottom: 3rem;
      border-bottom: 1px solid #eee;
      padding-bottom: 1rem;
    }

    header h1 {
      font-size: 2rem;
      margin-bottom: 0.8rem;
    }

    header h2 {
      font-weight: normal;
      font-size: 1.25rem;
      color: #666;
    }

    nav {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      gap: 1rem;
      margin-top: 1rem;
    }

    nav a {
      padding: 0.3rem 0.6rem;
      border: 1px solid #ccc;
      border-radius: 5px;
      transition: background-color 0.2s;
    }

    nav a:hover {
      background-color: #f8f8f8;
    }

    section {
      margin-bottom: 3rem;
    }

    section h3 {
      font-size: 1.5rem;
      margin-bottom: 1rem;
      border-left: 5px solid #0066cc;
      padding-left: 0.5rem;
    }

    p {
      margin-bottom: 1rem;
    }

    /* Image placeholders and gallery styling */
    .gallery {
      display: grid;
      gap: 1rem;
      grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
      margin-top: 1rem;
    }

    .gallery div {
      border: 1px solid #eee;
      padding: 1rem;
      background: #f9f9f9;
    }

    .gallery img {
      width: 100%;
      height: auto;
      display: block;
      margin-bottom: 0.5rem;
    }

    .placeholder {
      background: #ccc;
      width: 100%;
      height: 180px;
      display: block;
    }

    /* Footer */
    footer {
      text-align: center;
      padding: 1rem 0;
      font-size: 0.9rem;
      color: #666;
      border-top: 1px solid #eee;
    }

    /* Responsive behavior */
    @media (max-width: 600px) {
      header h1 {
        font-size: 1.5rem;
      }
      .container {
        width: 95%;
      }
    }
  </style>
</head>
<body>

<div class="container">
  <header>
    <h1>Diffusion Model Guided Sampling with Pixel-Wise Aleatoric Uncertainty Estimation</h1>
    <h2>By: Michele De Vita, Vasileios Belagiannis</h2>
    <nav>
      <a href="#">Paper (PDF Placeholder)</a>
      <a href="#">Code (Link Placeholder)</a>
    </nav>
  </header>

  <section id="overview">
    <h3>Overview</h3>
    <p>
      We explore a novel approach to guide the sampling phase of diffusion models by estimating pixel-wise 
      aleatoric uncertainty. In each denoising step, we compute the variance of the denoising scores and use 
      this to steer the generation toward high-quality images. This approach is shown to improve performance 
      in tasks like filtering out low-quality samples and guiding the sampling process itself.
    </p>
    <p>
      Our method is developed without training overhead, relying instead on a Monte Carlo style perturbation 
      scheme specifically tailored to diffusion models. We connect the estimated uncertainty to the second-order 
      derivatives (the curvature) of the noising distribution log-likelihood, yielding theoretical insights 
      and practical benefits in sample generation quality.
    </p>
  </section>

  <section id="gallery">
    <h3>Sample Placeholders</h3>
    <p>
      Below is a placeholder gallery showcasing generated images, where we compare “normal” diffusion sampling 
      vs. “uncertainty-guided” sampling. Each row demonstrates the model’s output under different conditions.
      (Note: All images are placeholders here.)
    </p>
    <div class="gallery">
      <div>
        <img class="placeholder" alt="Placeholder Image 1" />
        <small>Uncertainty-based generation sample placeholder</small>
      </div>
      <div>
        <img class="placeholder" alt="Placeholder Image 2" />
        <small>Non-guided generation sample placeholder</small>
      </div>
      <div>
        <img class="placeholder" alt="Placeholder Image 3" />
        <small>Uncertainty-based generation sample placeholder</small>
      </div>
    </div>
  </section>

  <section id="method">
    <h3>Method Highlights</h3>
    <p>
      Our approach begins with a straightforward observation: the diffusion model’s denoising scores can 
      be seen as approximations to the probability gradient of intermediate noisy images. By examining 
      how these scores vary under small perturbations, we quantify the aleatoric uncertainty for each pixel.
      Specifically, we: 
    </p>
    <ul>
      <li>Approximate the clean image at each timestep (via a single denoising step).</li>
      <li>Re-introduce noise multiple times and compute denoising scores.</li>
      <li>Leverage the variance of these scores to detect high-uncertainty pixels.</li>
    </ul>
    <p>
      Mathematically, the uncertainty map U<sub>t</sub> relates to the second derivative of the log noising 
      distribution. This theoretical connection enables direct sampling guidance, improving quality while 
      maintaining efficient computation.
    </p>
  </section>

  <section id="results">
    <h3>Results &amp; Findings</h3>
    <p>
      We evaluated on ImageNet and CIFAR-10, demonstrating that our uncertainty estimates can filter out 
      low-quality outputs with minimal overhead. Additionally, our “uncertainty-guided” sampling consistently 
      yields higher fidelity images compared to baseline diffusion sampling:
    </p>
    <ul>
      <li>
        <strong>Filtering Low-Quality Samples:</strong> Using the pixel-wise uncertainty, we discarded 
        samples above a threshold, improving overall sample quality in terms of FID scores.
      </li>
      <li>
        <strong>Uncertainty-Guided Sampling:</strong> By adaptively updating the denoising scores for 
        high-uncertainty pixels, we achieved better perceptual quality, corroborated by improved FID 
        and fewer visual artefacts.
      </li>
    </ul>
    <p>
      Detailed quantitative results, including AUSE and AURG metrics, provide evidence that our approach 
      outperforms related uncertainty-based diffusion model methods in both accuracy and efficiency.
    </p>
  </section>

  <section id="citation">
    <h3>Citation</h3>
    <pre>
    @misc{devita2024,
      title={Diffusion Model Guided Sampling with Pixel-Wise Aleatoric Uncertainty Estimation},
      author={M. De Vita and V. Belagiannis},
      year={2024},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
    }
    </pre>
  </section>

  <footer>
    <p>
      © 2025 Diffusion Model Guided Sampling Demo | 
      <a href="#">Placeholder Link</a> 
      | Inspired by DepthFM style reference.
    </p>
  </footer>
</div>

<!-- If you need any JavaScript for minor interactivity or placeholders, place it here -->
<script>
  // Currently no JS needed for the basic static placeholders,
  // but you could add slider or expand/collapse interactions here.
</script>
</body>
</html>